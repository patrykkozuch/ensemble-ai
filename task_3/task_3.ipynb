{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_img(img: np.ndarray, eps: float = 0.01) -> np.ndarray:\n",
    "    if len(img.shape) == 2:\n",
    "        return False\n",
    "\n",
    "    mg_diff_rg = np.abs(img[..., 0] - img[..., 1])\n",
    "    img_diff_gb = np.abs(img[..., 1] - img[..., 2])\n",
    "    img_diff_br = np.abs(img[..., 2] - img[..., 0])\n",
    "\n",
    "    img_diff_max = np.maximum(np.maximum(mg_diff_rg, img_diff_gb), img_diff_br)\n",
    "    is_skipped = img_diff_max.mean() > eps\n",
    "\n",
    "    # if is_skipped:\n",
    "    #     plt.imshow(img_diff_max)\n",
    "    #     plt.show()\n",
    "\n",
    "    return is_skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.ids_new = []\n",
    "        self.imgs_tensors = []\n",
    "        self.labels_tensors = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def compute_transform(self, should_skip: bool = True):\n",
    "        self.ids_new = []\n",
    "        self.imgs_tensors = []\n",
    "        self.labels_tensors = []\n",
    "\n",
    "        for id_, img, label in zip(self.ids, self.imgs, self.labels):\n",
    "            if should_skip and filter_img(np.array(img).astype(np.float32) / 255.0):\n",
    "                continue\n",
    "\n",
    "            img = (transforms.functional.pil_to_tensor(img).float() / 255.0)\n",
    "            if len(img.shape) == 2:\n",
    "                img = torch.stack((img,)*3, axis=-1)\n",
    "            elif img.shape[0] == 1:\n",
    "                img = torch.cat((img,)*3, axis=0)\n",
    "            self.imgs_tensors.append(img)\n",
    "\n",
    "            label_tensor = torch.tensor(label)\n",
    "            self.labels_tensors.append(label_tensor)\n",
    "\n",
    "            self.ids_new.append(id_)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids_new[index]\n",
    "        img = self.imgs_tensors[index]\n",
    "        label = self.labels_tensors[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.Normalize([0.2980, 0.2962, 0.2987], [0.2886, 0.2875, 0.2889]),\n",
    "])\n",
    "\n",
    "train_transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.RandomRotation(40),\n",
    "    v2.RandomAffine(0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=0.1),\n",
    "\n",
    "    v2.RandomChoice([\n",
    "        v2.GaussianBlur(3),\n",
    "        v2.GaussianBlur(5),\n",
    "        lambda x: x\n",
    "    ], p=[0.3, 0.3, 0.4]),\n",
    "\n",
    "    v2.ColorJitter(brightness=0.02, contrast=0.02, saturation=0.02, hue=0.01),\n",
    "\n",
    "    v2.Normalize([0.2980, 0.2962, 0.2987], [0.2886, 0.2875, 0.2889]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = torch.load('Train.pt', weights_only=False)\n",
    "all_dataset.compute_transform()\n",
    "\n",
    "train_size = int(0.9 * len(all_dataset))\n",
    "valid_size = len(all_dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(all_dataset, [train_size, valid_size])\n",
    "train_dataset.transform = train_transform\n",
    "valid_dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72988 18248\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=16, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=128, shuffle=True, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {}\n",
    "\n",
    "# for _, img, label in tqdm(train_dataset):\n",
    "#     label_value = int(label.item())\n",
    "#     if label_value not in labels:\n",
    "#         labels[label_value] = 1\n",
    "#     else:\n",
    "#         labels[label_value] += 1\n",
    "\n",
    "labels = {\n",
    "    8: 31802,\n",
    "    2: 23356,\n",
    "    5: 14886,\n",
    "    4: 7036,\n",
    "    1: 9171,\n",
    "    7: 409,\n",
    "    9: 4706,\n",
    "    3: 3568,\n",
    "    6: 4642,\n",
    "    0: 424\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: 31802,\n",
       " 2: 23356,\n",
       " 5: 14886,\n",
       " 4: 7036,\n",
       " 1: 9171,\n",
       " 7: 409,\n",
       " 9: 4706,\n",
       " 3: 3568,\n",
       " 6: 4642,\n",
       " 0: 424}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(labels.keys(), labels.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(2048, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([235.8491,  10.9039,   4.2816,  28.0269,  14.2126,   6.7177,  21.5424,\n",
      "        244.4988,   3.1445,  21.2495], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "total_count = sum(labels.values())\n",
    "class_weights = [total_count / labels[label] for label in sorted(labels.keys())]\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_some_worst_prediction_images(model: nn.Module, dataloader: DataLoader, limit_proba: float = 0.01) -> list[tuple[torch.Tensor, float]]:\n",
    "    worst_images_return = []\n",
    "\n",
    "    for _, imgs, labels in dataloader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        labels_pred_proba = torch.softmax(outputs, dim=1)\n",
    "        real_labels_proba = labels_pred_proba[torch.arange(labels.size(0)), labels]\n",
    "\n",
    "        is_worst = real_labels_proba < limit_proba\n",
    "        worst_images = imgs[is_worst]\n",
    "\n",
    "        for i in range(worst_images.size(0)):\n",
    "            worst_images_return.append((worst_images[i], real_labels_proba[i].item()))\n",
    "\n",
    "    return worst_images_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, images, labels, epsilon, criterion, min_val, max_val):\n",
    "    images.requires_grad = True\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    adv_images = images + epsilon * images.grad.sign()\n",
    "    \n",
    "    adv_images = torch.clamp(adv_images, min=min_val, max=max_val)\n",
    "    return adv_images.detach()\n",
    "\n",
    "def pgd_attack(model, images, labels, epsilon, num_steps, step_size, criterion, min_val, max_val):\n",
    "    adv_images = images.clone().detach()\n",
    "    adv_images.requires_grad_()\n",
    "    for _ in range(num_steps):\n",
    "        outputs = model(adv_images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        adv_images = adv_images + step_size * adv_images.grad.sign()\n",
    "        \n",
    "        perturbation = torch.clamp(adv_images - images, min=-epsilon, max=epsilon)\n",
    "        adv_images = images + perturbation\n",
    "        \n",
    "        adv_images = torch.clamp(adv_images, min=min_val, max=max_val)\n",
    "        \n",
    "        adv_images = adv_images.detach()\n",
    "        adv_images.requires_grad_()\n",
    "    return adv_images.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0326]],\n",
      "\n",
      "        [[-1.0303]],\n",
      "\n",
      "        [[-1.0339]]], device='cuda:0') tensor([[[2.4324]],\n",
      "\n",
      "        [[2.4480]],\n",
      "\n",
      "        [[2.4275]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "mean = [0.2980, 0.2962, 0.2987]\n",
    "std = [0.2886, 0.2875, 0.2889]\n",
    "\n",
    "mean_tensor = torch.tensor(mean).view(3, 1, 1).to(device)\n",
    "std_tensor = torch.tensor(std).view(3, 1, 1).to(device)\n",
    "min_val = ((0 - mean_tensor) / std_tensor)\n",
    "max_val = ((1 - mean_tensor) / std_tensor)\n",
    "\n",
    "print(min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, optimizer: optim.Optimizer, criterion, train_dataloader: DataLoader,\n",
    "          epochs: int, val_dataloader: DataLoader | None = None, epsilon: float = 0.03, alpha: float = 0.5,\n",
    "          num_steps: int = 5, step_size: float = 0.01,\n",
    "          alpha_clean: float = 0.33, alpha_fgsm: float = 0.33, alpha_pgd: float = 0.34):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total = 0\n",
    "\n",
    "        model.train()\n",
    "        for id_, img, label in tqdm(train_dataloader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # ###\n",
    "\n",
    "            # img.requires_grad = True\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            # outputs = model(img)\n",
    "\n",
    "            # class_loss = criterion(outputs, label)\n",
    "            # class_img_grad = torch.autograd.grad(class_loss, img, retain_graph=True)[0]\n",
    "            # new_img = img + epsilon * torch.sign(class_img_grad)\n",
    "            # new_img = torch.clamp(new_img, 0, 1)\n",
    "\n",
    "            # outputs_new = model(new_img)\n",
    "            # loss = alpha * criterion(outputs, label) + (1 - alpha) * criterion(outputs_new, label)\n",
    "\n",
    "            # ###\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs_clean = model(img)\n",
    "            loss_clean = criterion(outputs_clean, label)\n",
    "            \n",
    "            adv_imgs_fgsm = fgsm_attack(model, img, label, epsilon, criterion, min_val, max_val)\n",
    "            outputs_fgsm = model(adv_imgs_fgsm)\n",
    "            loss_fgsm = criterion(outputs_fgsm, label)\n",
    "\n",
    "            # Generate adversarial examples with PGD and compute loss\n",
    "            adv_imgs_pgd = pgd_attack(model, img, label, epsilon, num_steps, step_size, criterion, min_val, max_val)\n",
    "            outputs_pgd = model(adv_imgs_pgd)\n",
    "            loss_pgd = criterion(outputs_pgd, label)\n",
    "\n",
    "            loss = alpha_clean * loss_clean + alpha_fgsm * loss_fgsm + alpha_pgd * loss_pgd\n",
    "\n",
    "            # ###\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            predicted = torch.argmax(outputs_clean, dim=1)\n",
    "            total_correct += (predicted == label).sum().item()\n",
    "\n",
    "            total += len(label)\n",
    "\n",
    "        avg_loss = total_loss / total\n",
    "        accuracy = total_correct / total\n",
    "\n",
    "        if val_dataloader is not None:\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            total_val_correct = 0\n",
    "            total_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for _, img, label in val_dataloader:\n",
    "                    img = img.to(device)\n",
    "                    label = label.to(device)\n",
    "\n",
    "                    outputs = model(img)\n",
    "                    loss = criterion(outputs, label)\n",
    "\n",
    "                    total_val_loss += loss.item()\n",
    "                    predicted = torch.argmax(outputs, dim=1)\n",
    "                    total_val_correct += (predicted == label).sum().item()\n",
    "\n",
    "                    total_val += len(label)\n",
    "\n",
    "            avg_val_loss = total_val_loss / total_val\n",
    "            val_accuracy = total_val_correct / total_val\n",
    "            print(f'Epoch: {epoch} Loss: {avg_loss} Accuracy: {accuracy} Val Loss: {avg_val_loss} Val Accuracy: {val_accuracy}')\n",
    "        else:\n",
    "            print(f'Epoch: {epoch} Loss: {avg_loss} Accuracy: {accuracy}')\n",
    "            \n",
    "        loss_history.append(avg_loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "\n",
    "    return loss_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 571/571 [02:16<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.0578451462691468 Accuracy: 0.9912451361867705 Val Loss: 0.029688620661393116 Val Accuracy: 0.5562801402893468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 571/571 [02:15<00:00,  4.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.057589342811437294 Accuracy: 0.9917520688332329 Val Loss: 0.027271016275919303 Val Accuracy: 0.5611025865848313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 571/571 [02:16<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 0.05758563279386951 Accuracy: 0.9916561626568751 Val Loss: 0.03213879127661318 Val Accuracy: 0.571733888645331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 571/571 [02:15<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 0.057710527034434855 Accuracy: 0.9912999397161177 Val Loss: 0.0306540444486761 Val Accuracy: 0.5518960982025427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                            | 39/571 [00:11<02:41,  3.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      4\u001b[39m     param.requires_grad = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# for param in model.layer4.parameters():\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#     param.requires_grad = True\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m loss_history_new, acc_history_new = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss_history += loss_history_new\n\u001b[32m     11\u001b[39m acc_history += acc_history_new\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, criterion, train_dataloader, epochs, val_dataloader, epsilon, alpha, num_steps, step_size, alpha_clean, alpha_fgsm, alpha_pgd)\u001b[39m\n\u001b[32m     42\u001b[39m loss_fgsm = criterion(outputs_fgsm, label)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Generate adversarial examples with PGD and compute loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m adv_imgs_pgd = \u001b[43mpgd_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m outputs_pgd = model(adv_imgs_pgd)\n\u001b[32m     47\u001b[39m loss_pgd = criterion(outputs_pgd, label)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mpgd_attack\u001b[39m\u001b[34m(model, images, labels, epsilon, num_steps, step_size, criterion, min_val, max_val)\u001b[39m\n\u001b[32m     18\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     19\u001b[39m model.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m adv_images = adv_images + step_size * adv_images.grad.sign()\n\u001b[32m     23\u001b[39m perturbation = torch.clamp(adv_images - images, \u001b[38;5;28mmin\u001b[39m=-epsilon, \u001b[38;5;28mmax\u001b[39m=epsilon)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/tutorial004/ai/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/tutorial004/ai/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/net/tscratch/people/tutorial004/ai/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "loss_history, acc_history = train(model, optimizer, criterion, train_dataloader, 4, valid_dataloader)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# for param in model.layer4.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "loss_history_new, acc_history_new = train(model, optimizer, criterion, train_dataloader, 20, valid_dataloader)\n",
    "loss_history += loss_history_new\n",
    "acc_history += acc_history_new\n",
    "\n",
    "# for param in model.layer3.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "loss_history_new, acc_history_new = train(model, optimizer, criterion, train_dataloader, 30, valid_dataloader)\n",
    "loss_history += loss_history_new\n",
    "acc_history += acc_history_new\n",
    "\n",
    "# for param in model.layer2.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "loss_history_new, acc_history_new = train(model, optimizer, criterion, train_dataloader, 40, valid_dataloader)\n",
    "loss_history += loss_history_new\n",
    "acc_history += acc_history_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3806\n"
     ]
    }
   ],
   "source": [
    "worst_images = get_some_worst_prediction_images(model, valid_dataloader, 0.1)\n",
    "print(len(worst_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(worst_images[21][0].cpu().permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights_2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 clean: 0.5733333333333334 fgsm: 0.14433333333333334 pgd: 0.005666666666666667\n"
     ]
    }
   ],
   "source": [
    "# os.makedirs(\"out/models\", exist_ok=True)\n",
    "\n",
    "#### SUBMISSION ####\n",
    "\n",
    "# Create a dummy model\n",
    "# model = models.resnet50(weights=None)\n",
    "# model.fc = nn.Linear(model.fc.weight.shape[1], 10)\n",
    "# torch.save(model.state_dict(), \"out/models/dummy_submission.pt\")\n",
    "\n",
    "#### Tests ####\n",
    "# (these are being ran on the eval endpoint for every submission)\n",
    "\n",
    "allowed_models = {\n",
    "    \"resnet18\": models.resnet18,\n",
    "    \"resnet34\": models.resnet34,\n",
    "    \"resnet50\": models.resnet50,\n",
    "}\n",
    "with open(\"model_weights_2.pt\", \"rb\") as f:\n",
    "    try:\n",
    "        model: torch.nn.Module = allowed_models[\"resnet50\"](weights=None)\n",
    "        model.fc = torch.nn.Linear(model.fc.weight.shape[1], 10)\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Invalid model class, {e=}, only {allowed_models.keys()} are allowed\",\n",
    "        )\n",
    "    try:\n",
    "        state_dict = torch.load(f, map_location=torch.device(\"cpu\"))\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.eval()\n",
    "        out = model(torch.randn(1, 3, 32, 32))\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e=}\")\n",
    "\n",
    "    assert out.shape == (1, 10), \"Invalid output shape\"\n",
    "\n",
    "\n",
    "# Send the model to the server\n",
    "response = requests.post(\n",
    "    \"http://149.156.182.9:6060/task-3/submit\",\n",
    "    headers={\n",
    "        \"token\": \"i2SLZ1KbTzJeGkfPTWxE2Y53W9D0R5\",\n",
    "        \"model-name\": \"resnet50\"\n",
    "    },\n",
    "    files={\n",
    "        \"model_state_dict\": open(\"model_weights_2.pt\", \"rb\")\n",
    "    }\n",
    ")\n",
    "\n",
    "# Should be 400, the clean accuracy is too low\n",
    "print(response.status_code, response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
